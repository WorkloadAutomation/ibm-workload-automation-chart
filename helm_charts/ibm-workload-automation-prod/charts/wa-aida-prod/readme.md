
<!-- [ comment here   ] -->
# AI Data Advisor (AIDA) 
## Content
- [Introduction](#introduction)  
- [Details](#details)  
- [Limitations](#limitations) 
- [Supported Platforms](#supported-platforms)  
- [Accessing the container images](#accessing-the-container-images) 
- [Prerequisites](#prerequisites) 
- [Resources Required](#resources-required) 
- [Preparing for installation](#preparing-for-installation)
- [Installing](#installing) 
	 -  [Creating the Secret](#creating-the-secret)  	 
	 -  [ Verifying the installation](#verifying-the-installation)
-  [Upgrading the Chart](#upgrading-the-chart)   
-  [Rolling Back the Chart](#rolling-back-the-chart)   
-  [Uninstalling the Chart](#uninstalling-the-chart)
-  [Configuration Parameters](#configuration-parameters)
-  [Configuring](#configuring)
	 -  [ Network enablement](#network-enablement)	
	 - [Scaling the product](#scaling-the-product)	
-  [Storage](#storage)
	 -  [AIDA storage requirements](#aida-storage-requirements)	
	 -  [Persistent volume storage access modes](#persistent-volume-storage-access-modes)	
-  [Documentation](#documentation)
##  Introduction
**AI Data Advisor (AIDA)** is a new component of HCL Workload Automation V10.1, based on Artificial Intelligence and Machine Learning techniques. It enables fast and simplified data-driven decision making for an intelligent workload management. By analyzing workload historical data and metrics gathered by HCL Workload Automation and predicting their future patterns, AIDA identifies anomalies in KPIs trend (such as the jobs in plan by status and the jobs in plan by workstation) and sends immediate alerts to prevent problems and delays. Alerts show up on the Workload Dashboard and can be notified via email.
AIDA can be deployed into the following supported third-party cloud provider infrastructures:
-   ![Amazon EKS](images/tagawseks.png "Amazon EKS")
-   ![Microsoft Azure](images/tagmsa.png "Microsoft Azure")
-   ![Google GKE](images/taggke.png "Google GKE")
For more information about AIDA, see [AIDA User's Guide](https://help.hcltechsw.com/workloadautomation/v101/common/src_ai/awsaimst_welcome.html).
For information about HCL Workload Automation exposed metrics, see [Monitoring with Prometheus](https://help.hcltechsw.com/workloadautomation/v101/distr/src_ref/awsrgmonprom.html).   
This readme provides the steps for deploying AIDA, using helm charts and container images. Deploy AIDA after deploying HCL Workload Automation. For details about  HCL Workload Automation deployment, refer to HCL Workload Automation readme file. 
##  Limitations
* Limited to amd64 platforms.
* With AIDA deployment on Kubernetes, you can monitor only HCL Workload Automation servers (not HCL Workload Automation for Z servers).
* With AIDA deployment on Kubernetes, each single AIDA instance can monitor just one HCL Workload Automation server.  
* With AIDA deployment on Kubernetes, AIDA UI can be accessed only using the AIDA widget on the Workload Dashboard of the Dynamic Workload Console. 
##  Details
AIDA helm chart is composed of the following sub-charts, one for each service:
-   ``aida-ad`` - Anomaly detection and alert generation service    
-   ``aida-es`` - Elasticsearch, to store and analyze data    
-   ``aida-exporter`` - Exporter service    
-   ``aida-email`` - Email notification service    
-   ``aida-nginx`` - As a reverse proxy for AIDA components    
-   ``aida-orchestrator`` - Orchestrator service    
-   ``aida-predictor`` - Predictor service    
-   ``aida-redis`` - Internal event manager
-  `` aida-ui`` - AIDA UI
Each sub-chart defines the following Kubernetes resources:
**Deployments**
Each sub-chart except aida-es defines a deployment named
` {{ .Release.Name }}-{{ .Chart.Name }}`
**Pods**
Each Deployment generates one or more Pods  named 
`{{ .Release.Name }}-{{ .Chart.Name }}-<UID>` where <UID> is a Unique Identifier generated randomly by Kubernetes.
**Stateful Sets**
aida-es service defines a StatefulSet named 
`{{ .Release.Name }}-aida-es`
**Services**
Each sub-chart defines a service named
` {{ .Release.Name }}-{{ .Chart.Name }}` of kind ClusterIP.
**Persistent Volume Claims**
aida-es service defines a PVC generated by the Deployment that is named `{{ .Release.Name }}-aida-es`
**Persistent Volumes**
aida-es service generates a PV linked to the PVC if using Dynamic Provisioning, otherwise an existing PV can be used.
**Service Accounts**
Each sub-chart defines a ServiceAccount named 
`{{ .Release.Name }}-{{ .Chart.Name }}` if `serviceAccount.create` is true, otherwise an existing  `global.serviceAccountName` will be used.
**Ingress or Load Balancer or Route**
Depends on the type of network enablement that is configured. See [ Network enablement](#network-enablement).
##  Supported Platforms
-   ![Amazon EKS](images/tagawseks.png "Amazon EKS") Amazon Elastic Kubernetes Service (EKS) on amd64: 64-bit Intel/AMD x86
-   ![Microsoft Azure](images/tagmsa.png "Microsoft Azure") Azure Kubernetes Service (AKS) on amd64: 64-bit Intel/AMD x86
-   ![Google GKE](images/taggke.png "Google GKE") Google Kubernetes Engine (GKE) on amd64: 64-bit Intel/AMD x86
### Openshift support
You can deploy AIDA on Openshift 4.2 or later version by following the instruction in this documentation and using the helm chart. Ensure to modify the value of this parameter in the aida-nginx section of the ``values.yaml`` file:
`` aida-nginx.exposeServiceType``
from `LoadBalancer` to `Routes`
##  Accessing the container images
You can access AIDA subcharts and container images from the Entitled Registry. See [Creating the Secret](#creating-the-secret) for more information about accessing the registry. The images are as follows:
 - ``wa-registry.prod.hclpnp.com/wa-aida/aida-hcl/aida-ad:10.1.0.00`` 
 - ``wa-registry.prod.hclpnp.com/wa-aida/aida-hcl/aida-exporter:10.1.0.00``
 - ``wa-registry.prod.hclpnp.com/wa-aida/aida-hcl/aida-email:10.1.0.00``
 - ``wa-registry.prod.hclpnp.com/wa-aida/aida-hcl/aida-nginx:10.1.0.00``
 - ``wa-registry.prod.hclpnp.com/wa-aida/aida-hcl/aida-orchestrator:10.1.0.00``
 - ``wa-registry.prod.hclpnp.com/wa-aida/aida-hcl/aida-predictor:10.1.0.00``
 - ``wa-registry.prod.hclpnp.com/wa-aida/aida-hcl/aida-redis:10.1.0.00``
 - ``wa-registry.prod.hclpnp.com/wa-aida/aida-hcl/aida-ui:10.1.0.00``
##  Prerequisites
AIDA requires:
 -  HCL Workload Automation V101 exposed metrics
 -  API key for accessing the Entitled Registry: wa-registry.prod.hclpnp.com
 -  Open Distro for ElasticSearch V1.3.3
AIDA prerequisites are inherited by HCL Workload Automation V10.1. 
##  Resources Required
 The following resources correspond to the default values required to manage a production environment. These numbers might vary depending on the environment.
| Component | Container resource limit | Container memory request |
|--|--|--|
|**aida-ad**  | CPU: 2, Memory: 8Gi |CPU: 0.5, Memory: 1Gi, Storage: n/a  |
|**aida-es**  | CPU: 4, Memory: 8Gi  |CPU: 0.5, Memory: 1Gi, Storage: 10Gi  |
|**aida-exporter** |CPU: 2, Memory: 4Gi |CPU: 0.5, Memory: 0.5Gi, Storage: n/a  |
|**aida-email** |CPU: 1, Memory: 2Gi |CPU: 200m, Memory: 0.5Gi, Storage: n/a  |
|**aida-nginx** |CPU: 1, Memory: 1Gi |CPU: 200m, Memory: 200Mi, Storage: n/a  |
|**aida-orchestrator** |CPU: 2, Memory: 4Gi |CPU: 0.5, Memory: 0.5Gi, Storage: n/a  |
|**aida-predictor** |CPU: 8, Memory: 16Gi |CPU: 1, Memory: 1Gi, Storage: n/a  |
|**aida-redis** |CPU: 1, Memory: 500Mi |CPU: 200m, Memory: 200Mi, Storage: n/a  |
|**aida-ui** |CPU: 1, Memory: 2Gi |CPU: 0.3, Memory: 0.5Gi, Storage: n/a  |
##  Preparing for installation
Before installing AIDA, run the following steps: 
1.  Accept the product license by setting the global.license parameter to "accept" (default value is "notaccepted") in the values.yaml file.
2.  To use custom SSL certificates for AIDA, in the <install_path>/nginx/cert folder replace aida.crt e aida.key with your own files (do not change the default names).
3.  Verify that aida-exporter.waHostName parameter in the values.yaml file is set to the host name used to reach the WA server. This parameter is not required if AIDA is deployed in the same helm chart as WA.
4.  Verify that aida-exporter.waPort parameter in the values.yaml file is set to the port used to reach the WA server. Its default value is "3116".   
5.  Verify that aida-nginx.waConsoleCertSecretName parameter in the values.yaml file is set to the name of the WA console secret used to store the customized SSL certificates.
6.  If you want to receive alert notification via email, properly set the configuration parameters in the aida-email section of the values.yaml file.  
##  Installing
Refer to HCL Workload Automation readme file for the general installation procedure that  includes AIDA as an HCL Workload Automation component.
In addition, run the following AIDA specific steps: 
1. [Creating the  Secret](#creating-the-secret) by accessing the entitled registry to store an entitlement key for AIDA offering on your cluster.
2. [Verifying the installation](#verifying-the-installation).
### Creating the Secret
If you already have a license, then you can proceed to obtain your entitlement key. To learn more about acquiring an HCL Workload Automation license, contact [HWAinfo@hcl.com](mailto:HWAinfo@hcl.com).
Obtain your entitlement key and store it on your cluster by creating a [Kubernetes Secret](https://kubernetes.io/docs/concepts/configuration/secret/). Using a Kubernetes secret allows you to securely store the key on your cluster and access the registry to download the chart and product images.
1.  Access the entitled registry. Contact your HCL sales representative for the login details required to access the HCL Entitled Registry: wa-registry.prod.hclpnp.com.
3.  To create a pull secret for your entitlement key that enables access to the entitled registry, run the following command:
    ``      kubectl create secret docker-registry -n <workload_automation_namespace> sa-<workload_automation_namespace> --docker-server=<registry_server> --docker-username=<user_name> --docker-password=<password>    ``
    where,
    -   `<workload_automation_namespace>` represents the namespace where the product components are installed
    -   `<registry_server>` is `wa-registry.prod.hclpnp.com`
    -   `<user_name>` is the user name provided by your HCL representative
    -   `<password>` is the entitled key copied from the entitled registry `<api_key>`
###  Verifying the installation
After the deployment procedure is complete, you can validate the deployment to ensure that AIDA is working. 
To manually verify that AIDA was successfully installed, you can perform the following checks: 
1. Run the following command to verify the AIDA pods (see [Details](#details)) installed in the <workload_automation_namespace>:
           kubectl get pods -n <workload_automation_namespace>
2. Verify that AIDA UI is accessible using the AIDA widget on the Workload Dashboard of the Dynamic Workload Console. 	
 ![aida widget](images/AIDA_widget.png)	   
##  Upgrading the Chart
Refer to HCL Workload Automation readme file.
##  Rolling Back the Chart
Refer to HCL Workload Automation readme file.
##  Uninstalling the Chart
Refer to HCL Workload Automation readme file.
##  Configuration Parameters
The following tables list the configurable parameters of the chart **values.yaml**, and their default values. The tables are organized as follows:
- **[Global parameters](#global-parameters)**
- **[AIDA parameters](#aida-parameters)**
&nbsp;
 - ### Global parameters
The following table lists the global configurable parameters of the chart and their default values:
| **Parameter** | **Description** | **Mandatory** | **Example** | **Default** |
| --------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------- | -------------------------------- | -------------------------------- |
|license |Use "accept" to agree to the license agreement | yes |notaccepted   | notaccepted |
|serviceAccountName|The name of the serviceAccount to use. The HCL Workload Automation default service account (wauser) and not the default cluster account| no | wauser | default
|aidaEngineLogLevel |Log level in AIDA. Can be DEBUG, INFO, ERROR, WARNING, CRITICAL | yes |"INFO"  |"INFO"  |
|redisPwd|aida-redis passowrd  | yes |"foobared"  |"foobared" |
|defaultShardCount | The default number of Elasticsearch shards |yes | 1 |1  |
- ### AIDA parameters
The following tables list the configurable parameters of the chart relative to each service and their default values:
 ### [aida-ad parameters](#aida-ad-parameters)
| **Parameter** | **Description** | **Mandatory** | **Example** | **Default** |
| ------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------- | -------------------------------- | -------------------------------- |
|image.repository|aida-ad image repository  |yes  | @DOCKER.AGENT.IMAGE.NAME@ |  wa-registry.prod.hclpnp.com/wa-aida/aida-hcl/aida-ad |
|image.tag | aida-ad image tag | yes |@VERSION@  | 10.1 |
|image.pullPolicy | image pull policy |yes  |Always | Always |
|serviceAccount.create | If true, a new ServiceAccount will be created, if false will be used an existing one with name global.serviceAccountName |  no | false |false |
|serviceAccount.annotations | Annotations to add to the created ServiceAccount | no | kubernetes.io/service-account.name: sa-name |{} |
|serviceAccount.name | The name of the created ServiceAccount. If not set, the Pod name will be used instead. | no | sa-name |"" |
|resources.limits.cpu |The maximum CPU requested to run   | no| 2 |2 |
|resources.limits.memory |The maximum memory requested to run | no  | 8Gi |8Gi |
|resources.requests.cpu |The minimum CPU requested to run | no  | 0.5 |0.5 |
|resources.requests.memory |The minimum memory requested to run | no  | 1Gi |1Gi |
|autoscaling.enabled |Set this to **false** to completely disable autoscaling and **true** to enable it | no  | true |true |
|autoscaling.minReplicas |The minimum number of Pods | no  | 1 |1 |
|autoscaling.maxReplicas |The maximum number of Pods | no  | 10 |10 |
|autoscaling.targetMemoryUtilizationPercentage |The value in percentage of memory utilization that each Pod should have | no  | 80 |80 |
 ### [aida-es parameters](#aida-es-parameters)
| **Parameter** | **Description** | **Mandatory** | **Example** | **Default** |
| ------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------- | -------------------------------- | -------------------------------- |
|esDiscoveryType| Set this to "single-node" for single node clusters and leave unset for multi-node. | yes | single-node |  single-node |
|image.repository|aida-es image repository  |yes  |@DOCKER.AGENT.IMAGE.NAME@  |  wa-registry.prod.hclpnp.com/wa-aida/aida-hcl/aida-es |
|image.tag | aida-es image tag | yes |@VERSION@  | 10.1 |
|image.pullPolicy | image pull policy |yes  |Always | Always |
|serviceAccount.create |If true, a new ServiceAccount will be created, if false will be used an existing one with name global.serviceAccountName | no|false  |false |
|serviceAccount.annotations | Annotations to add to the created ServiceAccount | no | kubernetes.io/service-account.name: sa-name |{} |
|serviceAccount.name | The name of the created ServiceAccount. If not set, the Pod name will be used instead. | no | sa-name |"" |
|persistence.enabled | If true, StorageClasses are used to dynamically create persistent volumes for the pods |no   |true  |true |
|persistence.useDynamicProvisioning | If true, StorageClasses are used to dynamically create persistent volumes for the pods | no  |true  |true |
|persistence.dataPVC.storageClassName |The name of the Storage Class to be used. Leave empty to not use a storage class |no   |nfs-dynamic  |"" |
|persistence.dataPVC.selector.label |Volume label to bind (only limited to single label)        | no  |my-volume-label  |"" |
|persistence.dataPVC.selector.value |Volume label value to bind (only limited to single value) | no  |my-volume-value  |"" |
|persistence.dataPVC.size |The minimum size of the Persistent Volume | no |10Gi|10Gi|
|resources.limits.cpu |The maximum CUP requested to run   | yes|4  |4 |
|resources.limits.memory |The maximum memory requested to run | yes  |8Gi  |8Gi |
|resources.requests.cpu |The minimum CPU requested to run | yes  | 0.5 |0.51 |
|resources.requests.memory |The minimum memory requested to run | yes  | 1Gi |1Gi |
 ### [aida-exporter parameters](#aida-exporter-parameters)
| **Parameter** | **Description** | **Mandatory** | **Example** | **Default** |
| ------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------- | -------------------------------- | -------------------------------- |
|waHostName|The host name used to reach the WA server. Not required if WA is deployed in the same helm chart as AIDA.   |no  | wa-hostname.com | "" |
|waPort|The port used to reach the WA server   |yes  |31116  | 31116  |
|httpAuthUsername| The username of WA basic authentication.  | yes | wauser | wauser |
|httpAuthPasswordSecretName| The name of the secret that stores the password of WA basic authentication.  | yes | wa-pwd-secret | wa-pwd-secret  |
|image.repository|aida-exporter image repository  |yes  | @DOCKER.AGENT.IMAGE.NAME@ |  wa-registry.prod.hclpnp.com/wa-aida/aida-hcl/aida-exporter |
|image.tag | aida-exporter image tag | yes |@VERSION@  | 10.1 |
|image.pullPolicy | image pull policy |yes  |Always | Always |
|serviceAccount.create |If true, a new ServiceAccount will be created, if false will be used an existing one with name global.serviceAccountName |no   |false  |false |
|serviceAccount.annotations | Annotations to add to the created ServiceAccount | no | kubernetes.io/service-account.name: sa-name |{} |
|serviceAccount.name | The name of the created ServiceAccount. If not set, the Pod name will be used instead. | no | sa-name |"" |
|resources.limits.cpu |The maximum CUP requested to run   | yes| 2 |2 |
|resources.limits.memory |The maximum memory requested to run | yes  |4Gi  |4Gi |
|resources.requests.cpu |The minimum CPU requested to run | yes  | 0.5 |0.5 |
|resources.requests.memory |The minimum memory requested to run | yes  |0.5Gi  |0.5Gi |
### [aida-email parameters](#aida-email-parameters)
| **Parameter** | **Description** | **Mandatory** | **Example** | **Default** |
| ------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------- | -------------------------------- | -------------------------------- |
|smtpServer|The smtp server   | yes | "smtp-mail.outlook.com" | "smtp.server.com"  |
|smtpPort|The port of the smtp server  | yes | 587 | 587  |
|senderEmailId| The email account of the alert sender   | yes |`"john@outlook.com"`  |  `"smtp@server.com"` |
|senderEmailPwd|The email password of the alert sender   | yes |"pwd"  |  "smtpPassword" |
|recipientMailIds|The list of recipient emails   | yes |`"jack@gmail.com,jessie@live.com"`  | `"mail1@mail.com,mail2@mail.com"` |
|image.repository|aida-email image repository  |yes  |@DOCKER.AGENT.IMAGE.NAME@  |  wa-registry.prod.hclpnp.com/wa-aida/aida-hcl/aida-exporter |
|image.tag | aida-exporter image tag | yes |@VERSION@  | 10.1 |
|image.pullPolicy | image pull policy |yes  |Always | Always |
|serviceAccount.create |If true, a new ServiceAccount will be created, if false will be used an existing one with name global.serviceAccountName | no|false|false |
|serviceAccount.annotations | Annotations to add to the created ServiceAccount | no | kubernetes.io/service-account.name: sa-name |{} |
|serviceAccount.name | The name of the created ServiceAccount. If not set, the Pod name will be used instead. | no | sa-name |"" |
|resources.limits.cpu |The maximum CUP requested to run   | yes|1  |1 |
|resources.limits.memory |The maximum memory requested to run | yes  | 2Gi |2Gi |
|resources.requests.cpu |The minimum CPU requested to run | yes  |200m  |200m |
|resources.requests.memory |The minimum memory requested to run | yes  |0.5Gi  | 0.5Gi|
### [aida-nginx parameters](#aida-nginx-parameters)
| **Parameter** | **Description** | **Mandatory** | **Example** | **Default** |
| ------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------- | -------------------------------- | -------------------------------- |
|waConsoleCertSecretName|The name of the WA console secret to store customized SSL certificates  |yes  |waconsole-cert-secret  | waconsole-cert-secret |
|image.repository|aida-nginx image repository  |yes  |@DOCKER.AGENT.IMAGE.NAME@  |  wa-registry.prod.hclpnp.com/wa-aida/aida-hcl/aida-nginx |
|image.tag | aida-nginx image tag | yes |@VERSION@  | 10.1 |
|image.pullPolicy | image pull policy |yes  |Always | Always |
|serviceAccount.create |If true, a new ServiceAccount will be created, if false will be used an existing one with name global.serviceAccountName |no |false|false |
|serviceAccount.annotations | Annotations to add to the created ServiceAccount | no | kubernetes.io/service-account.name: sa-name |{} |
|serviceAccount.name | The name of the created ServiceAccount. If not set, the Pod name will be used instead. | no | sa-name |"" |
|routes.enabled |If true, the ingress controller rules are enabled  | no  | true |true |
|ingress.hostname|The virtual hostname defined in the DNS used to reach the WA Console   | yes, only if the network enablement implementation is INGRESS   | aida.com | |
|ingress.secretName|The WA Console ingress secret | yes, only if the network enablement implementation is INGRESS   |wa-console-ingress-secret  | wa-console-ingress-secret|
|exposeServiceType |The network enablement configuration implemented. Valid values: LoadBalancer, Ingress or Routes     | yes| LoadBalancer |LoadBalancer |
|exposeServiceAnnotation |Annotations of either the resource of the service or the resource of the ingress, customized in accordance with the cloud provider       | yes| networking.gke.io/load-balancer-type: "Internal" | {} |
|resources.limits.cpu |The maximum CUP requested to run   | yes| 1 |1 |
|resources.limits.memory |The maximum memory requested to run | yes  |1Gi  |1Gi |
|resources.requests.cpu |The minimum CPU requested to run | yes  |200m  |200m |
|resources.requests.memory |The minimum memory requested to run | yes  |200Mi  | 200Mi|
### [aida-orchestrator parameters](#aida-orchestrator-parameters)
| **Parameter** | **Description** | **Mandatory** | **Example** | **Default** |
| ------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------- | -------------------------------- | -------------------------------- |
|image.repository|aida-orchestrator image repository  |yes  |@DOCKER.AGENT.IMAGE.NAME@  |  wa-registry.prod.hclpnp.com/wa-aida/aida-hcl/aida-orchestrator |
|image.tag | aida-ad image tag | yes |@VERSION@  | 10.1 |
|image.pullPolicy | image pull policy |yes  |Always | Always |
|serviceAccount.create |If true, a new ServiceAccount will be created, if false will be used an existing one with name global.serviceAccountName |no |false|false |
|serviceAccount.annotations | Annotations to add to the created ServiceAccount | no | kubernetes.io/service-account.name: sa-name |{} |
|serviceAccount.name | The name of the created ServiceAccount. If not set, the Pod name will be used instead. | no | sa-name |"" |
|resources.limits.cpu |The maximum CUP requested to run   | yes| 2 |2 |
|resources.limits.memory |The maximum memory requested to run | yes  |4Gi  |4Gi |
|resources.requests.cpu |The minimum CPU requested to run | yes  | 0.5 |0.5 |
|resources.requests.memory |The minimum memory requested to run | yes  |0.5Gi  |0.5Gi |
### [aida-predictor parameters](#aida-predictor-parameters)
| **Parameter** | **Description** | **Mandatory** | **Example** | **Default** |
| ------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------- | -------------------------------- | -------------------------------- |
|image.repository|aida-predictor image repository  |yes  |@DOCKER.AGENT.IMAGE.NAME@  |  wa-registry.prod.hclpnp.com/wa-aida/aida-hcl/aida-predictor |
|image.tag | aida-ad image tag | yes |@VERSION@  | 10.1 |
|image.pullPolicy | image pull policy |yes  |Always | Always |
|serviceAccount.create |If true, a new ServiceAccount will be created, if false will be used an existing one with name global.serviceAccountName |no|false|false |
|serviceAccount.annotations | Annotations to add to the created ServiceAccount | no | kubernetes.io/service-account.name: sa-name |{} |
|serviceAccount.name | The name of the created ServiceAccount. If not set, the Pod name will be used instead. | no | sa-name |"" |
|resources.limits.cpu |The maximum CUP requested to run   | yes| 8 |8 |
|resources.limits.memory |The maximum memory requested to run | yes  |16Gi  |16Gi |
|resources.requests.cpu |The minimum CPU requested to run | yes  | 1 |1 |
|resources.requests.memory |The minimum memory requested to run | yes  |1Gi  |1Gi |
|autoscaling.enabled |Set this to **false** to completely disable autoscaling and **true** to enable it | no  |true  |true |
|autoscaling.minReplicas |The minimum number of Pods | no  |1  |1 |
|autoscaling.maxReplicas |The maximum number of Pods | no  | 10 |10 |
|autoscaling.targetMemoryUtilizationPercentage |The value in percentage of memory utilization that each Pod should have | no  |80  |80 |
### [aida-redis parameters](#aida-redis-parameters)
| **Parameter** | **Description** | **Mandatory** | **Example** | **Default** |
| ------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------- | -------------------------------- | -------------------------------- |
|image.repository|aida-redis image repository  |yes  |@DOCKER.AGENT.IMAGE.NAME@  |  wa-registry.prod.hclpnp.com/wa-aida/aida-hcl/aida-redis |
|image.tag | aida-ad image tag | yes |@VERSION@  | 10.1 |
|image.pullPolicy | image pull policy |yes  |Always | Always |
|serviceAccount.create |If true, a new ServiceAccount will be created, if false will be used an existing one with name global.serviceAccountName |no|false|false |
|serviceAccount.annotations | Annotations to add to the created ServiceAccount | no | kubernetes.io/service-account.name: sa-name |{} |
|serviceAccount.name | The name of the created ServiceAccount. If not set, the Pod name will be used instead. | no | sa-name |"" |
|resources.limits.cpu |The maximum CUP requested to run   | yes|1  |1 |
|resources.limits.memory |The maximum memory requested to run | yes  |500Mi  |500Mi |
|resources.requests.cpu |The minimum CPU requested to run | yes  |200m  |200m |
|resources.requests.memory |The minimum memory requested to run | yes  |200Mi  |200Mi |
### [aida-ui parameters](#aida-ui-parameters)
| **Parameter** | **Description** | **Mandatory** | **Example** | **Default** |
| ------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------- | -------------------------------- | -------------------------------- |
|uiLogLevel |Log level in AIDA UI.  | no |  |"ERROR:*,INFO:*,-TRACE:*"  |
|image.repository|aida-ui image repository  |yes  |@DOCKER.AGENT.IMAGE.NAME@  |  wa-registry.prod.hclpnp.com/wa-aida/aida-hcl/aida-ui |
|image.tag | aida-ad image tag | yes |@VERSION@  | 10.1 |
|image.pullPolicy | image pull policy |yes  |Always | Always |
|serviceAccount.create |If true, a new ServiceAccount will be created, if false will be used an existing one with name global.serviceAccountName |no |false|false |
|serviceAccount.annotations | Annotations to add to the created ServiceAccount | no | kubernetes.io/service-account.name: sa-name |{} |
|serviceAccount.name | The name of the created ServiceAccount. If not set, the Pod name will be used instead. | no | sa-name |"" |
|resources.limits.cpu |The maximum CUP requested to run   | yes|1  |1 |
|resources.limits.memory |The maximum memory requested to run | yes  |2Gi  |2Gi |
|resources.requests.cpu |The minimum CPU requested to run | yes  |0.3  |0.3 |
|resources.requests.memory |The minimum memory requested to run | yes  |0.5Gi   |0.5Gi |
|autoscaling.enabled |Set this to **false** to completely disable autoscaling and **true** to enable it | no  |true  |true |
|autoscaling.minReplicas |The minimum number of Pods |no   |1  |1 |
|autoscaling.maxReplicas |The maximum number of Pods | no  |10  |10 |
|autoscaling.targetMemoryUtilizationPercentage |The value in percentage of memory utilization that each Pod should have |no  |80  |80 |
##  Configuring
The following procedures are ways in which you can configure AIDA default deployment. They include the following configuration topics:
* [Network enablement](#network-enablement)
* [Scaling the product](#scaling-the-product)
###  Network enablement
aida-nginx service can use two different ways to route external traffic into the Kubernetes Service cluster:
* A **load balancer** service that redirects traffic
* An **ingress** service that manages external access to the services in the cluster
You can freely switch between these two types of configuration.
####  Load balancer service
To configure a load balancer for aida-nginx service, follow these steps:
1. Locate the following parameters in the aida-nginx section of the `values.yaml` file:
`aida-nginx.exposeServiceType`
`aida-nginx.exposeServiceAnnotation`
For more information about these configurable parameters, see the [aida-nginx parameters](aida-nginx-parameters) table.
2. Set the value of the `exposeServiceType` parameter to `LoadBalancer`.
**Note:** You can also set the value of the `exposeServiceType` parameter to  `LoadBalancer_sessionAffinity` for Azure AKS and Google GKE. This parameter ensures each user session always remains active on the same pod, providing a smooth and seamless user experience.
3. In the `exposeServiceAnnotation` section, uncomment the lines in this section as follows:
![Amazon EKS](images/tagawseks.png "Amazon EKS") 
		service.beta.kubernetes.io/aws-load-balancer-backend-protocol: https
		service.beta.kubernetes.io/aws-load-balancer-type: "clb"
		#service.beta.kubernetes.io/aws-load-balancer-type: "nlb"
		service.beta.kubernetes.io/aws-load-balancer-internal: "true"
![Microsoft Azure](images/tagmsa.png "Microsoft Azure") 
		service.beta.kubernetes.io/azure-load-balancer-internal: "true"		
![Google GKE](images/taggke.png "Google GKE") 
		networking.gke.io/load-balancer-type: "Internal"
4. Specify the load balancer type and set the load balancer to internal by specifying "true".
####  Ingress service
To configure an ingress for aida-nginx service, follow these steps:
1. Locate the following parameters in the aida-nginx section of the `values.yaml` file: 
`aida-nginx.exposeServiceType`
`aida-nginx.exposeServiceAnnotation`
For more information about these configurable parameters, see the [aida-nginx parameters](#aida-nginx-parameters) table.
2. Set the value of the `exposeServiceType`parameter to `Ingress`.
3. In the `exposeServiceAnnotation` section, leave the following lines as comments:
![Amazon EKS](images/tagawseks.png "Amazon EKS") 
		#service.beta.kubernetes.io/aws-load-balancer-type:nlb
		#service.beta.kubernetes.io/aws-load-balancer-internal: "true"
![Microsoft Azure](images/tagmsa.png "Microsoft Azure")
		#service.beta.kubernetes.io/azure-load-balancer-internal: "true"	
![Microsoft Azure](images/taggke.png "Microsoft Azure")
                #networking.gke.io/load-balancer-type: "Internal"
### Scaling the product 
Scaling is only supported by the following services:
-   aida-ad    
-   aida-predictor    
-   aida-ui
It is enabled by default, and it is not possible to enable it on the other services.
#### Proportional scaling
For the services that support scaling, it is enabled by default the Kubernetes autoscaling feature, that automatically scales the  Pod count based on CPU or RAM utilization.
In AIDA `value.yaml` file, under the specific service section, you can change the following values to control autoscaling:
`autoscaling.enabled`: set this to false to completely disable autoscaling and true to enable it
`autoscaling.minReplicas`: set the minimum number of Pods
`autoscaling.maxReplicas`: set the maximum number of Pods
`autoscaling.targetMemoryUtilizationPercentage`: set the value in percentage of memory utilization that each Pod should have.
`autoscaling.targetCPUUtilizationPercentage`: set the value in percentage of CPU utilization that each Pod should have.
Kubernetes autoscaling feature will automatically increase the number of Pods if the actual utilization of CPU/RAM is higher than the configured target, and decrease the number of Pods if it is lower.
##  Storage
###  AIDA storage requirements 
AIDA requires persistent storage for the aida-es component that is an Elasticsearch database. 
To make all of the configuration and runtime data persistent, the Persistent Volume you specify must be mounted in the following container folder:
`/usr/share/elasticsearch/data/`
The Pod is based on a StatefulSet. This guarantees that each Persistent Volume is mounted in the same Pod when it is scaled up or down.
For test purposes only, you can configure the chart so that persistence is not used.
AIDA can use either dynamic provisioning or static provisioning using a pre-created persistent volume  
to allocate storage. You can pre-create Persistent Volumes to be bound to the StatefulSet using Label or StorageClass. It is highly recommended to use persistence with dynamic provisioning. In this case, you must have defined your own Dynamic Persistence Provider. AIDA supports the following provisioning use cases:
-   Kubernetes dynamic volume provisioning to create both a persistent volume and a persistent volume claim. 
This type of storage uses the default storageClass defined by the Kubernetes admin or by using a custom storageClass which overrides the default. Set the values as follows:
	-   **aida-es.persistence.enabled:true** (default)
	-   **aida-es.persistence.useDynamicProvisioning:true**  (default)
Specify a custom storageClassName or leave the value blank to use the default storageClass.
-   Persistent storage using a predefined PersistentVolume set up prior to the deployment of this chart. Pre-create a persistent volume. If you configure the label=value pair described in the following **Note**, then the persistent volume claim is automatically generated by the Helm chart and bound to the persistent volume you pre-created. Set the values as follows:
	-   **aida-es.persistence.enabled:true**
	-   **aida-es.persistence.useDynamicProvisioning:false**
**Note**: By configuring the following two parameters, the persistent volume claim is automatically generated. Ensure that this label=value pair is inserted in the persistent volume you created:
-   **aida-es.persistence.dataPVC.selector.label**
-   **aida-es.persistence.dataPVC.selector.value**
Let the Kubernetes binding process select a pre-existing volume based on the accessMode and size. Use selector labels to refine the binding process.
Before you deploy all of the components, you have the opportunity to choose your persistent storage from the available persistent storage options in your cloud environment or you can leave the default storageClass.
If you create a storageClass object or use the default one, ensure that you have a sufficient amount of backing storage for the aida-es component.  
For more information about the required amount of storage, see  [Resources Required](#resources-required). 
_Custom storage class:_   
Modify the `aida-es.persistence.dataPVC.storageClassName`
 parameter in the `value.yaml` file by specifying the custom storage class name, when you deploy aida-es component.
_Default storage class_:  
Leave the values for the `aida-es.persistence.dataPVC.storageClassName` 
parameter blank in the `value.yaml` file when you deploy aida-es component.  
For more information about the storage parameter values to set, see the [aida-es parameters](#aida-es-parameters) table.
###  Persistent volume storage access modes
AIDA supports only ReadWriteOnce (RWO) access mode. The volume can be mounted as read-write by a single node.
##  Documentation
For more information about AIDA, see [AIDA User's Guide](https://help.hcltechsw.com/workloadautomation/v101/common/src_ai/awsaimst_welcome.html).
